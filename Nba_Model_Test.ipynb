{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83a968a9",
   "metadata": {},
   "source": [
    "Nba PlayerStats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dd5eaee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import shap\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "\n",
    "\n",
    "df_advanced = pd.read_csv('/Users/lilgl/Downloads/BrainStation_Final_Project/2021-22 Advanced.csv')\n",
    "df_perGame = pd.read_csv('/Users/lilgl/Downloads/BrainStation_Final_Project/nba2022_2023 Per game.csv')\n",
    "df_standings = pd.read_csv('/Users/lilgl/Downloads/BrainStation_Final_Project/nba2022_2023 Standings.csv')\n",
    "df_total = pd.read_csv('/Users/lilgl/Downloads/BrainStation_Final_Project/nba2022_2023 Totals.csv')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4dfce2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the seasons and models used\n",
    "seasons = ['2021-22','2020-21','2019-20','2018-19','2017-18','2016-17','2015-16','2014-15','2013-14',\n",
    "          '2012-13','2011-12','2010-11','2009-10','2008-09','2007-08','2006-07'] \n",
    "          \n",
    "modelos = ['SVM','Elastic Net','Random Forest','AdaBoost','Gradient Boosting','LGBM']\n",
    "\n",
    "# Path to local folder\n",
    "path_data = r'D:\\Gabriel\\Documentos\\Modelo MVP'\n",
    "\n",
    "sep = r'/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dbd762ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(seasons):\n",
    "    \n",
    "    # Opening the data\n",
    "    per_game = pd.DataFrame()\n",
    "    totals = pd.DataFrame()\n",
    "    advanceds = pd.DataFrame()\n",
    "    standings = pd.DataFrame()\n",
    "\n",
    "    for season in seasons:\n",
    "      pergame = pd.read_csv('/Users/lilgl/Downloads/BrainStation_Final_Project/nba2022_2023 Per game.csv')\n",
    "\n",
    "      total = pd.read_csv('/Users/lilgl/Downloads/BrainStation_Final_Project/nba2022_2023 Totals.csv')\n",
    "      \n",
    "      advanced = pd.read_csv('/Users/lilgl/Downloads/BrainStation_Final_Project/nba2022_2023 Advanced.csv')\n",
    "      \n",
    "      standing = pd.read_csv('/Users/lilgl/Downloads/BrainStation_Final_Project/nba2022_2023 Standings.csv')\n",
    "      \n",
    "      \n",
    "      pergame['Season'] = season\n",
    "      total['Season'] = season\n",
    "      advanced['Season'] = season\n",
    "      standing['Season'] = season\n",
    "      \n",
    "      per_game = pd.concat([per_game,pergame], ignore_index=True)\n",
    "      totals = pd.concat([totals,total], ignore_index=True)\n",
    "      advanceds = pd.concat([advanceds,advanced], ignore_index=True)\n",
    "      standings = pd.concat([standings,standing], ignore_index=True)\n",
    "\n",
    "    return per_game, totals, advanceds, standings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "aab0a4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def treat_data(per_game, totals, avancados, standings, seasons):\n",
    "    \n",
    "    # Removing duplicate/empty columns\n",
    "    per_game = per_game.drop(['Rk','Pos'], axis=1)\n",
    "    totals = totals.drop(['Rk','Pos','Age','G','GS'], axis=1)\n",
    "    avancados = avancados.drop(['Rk','Pos','Age','G','MP','Unnamed: 24','Unnamed: 19'], axis=1)\n",
    "    \n",
    "    cols = ['Player','Season','Pos','Age','Tm','G','GS']\n",
    "    \n",
    "    # Identifying the variables\n",
    "    for coluna in per_game.columns:\n",
    "        if coluna not in cols:\n",
    "            nova_coluna = coluna+'_PERGAME'\n",
    "            per_game = per_game.rename(columns={coluna:nova_coluna})\n",
    "    for coluna in totals.columns:\n",
    "        if coluna not in cols:\n",
    "            nova_coluna = coluna+'_TOTAL'\n",
    "            totals = totals.rename(columns={coluna:nova_coluna})\n",
    "    for coluna in avancados.columns:\n",
    "        if coluna not in cols:\n",
    "            nova_coluna = coluna+'_AVANCADO'\n",
    "            avancados = avancados.rename(columns={coluna:nova_coluna})\n",
    "    \n",
    "    # Merging the bases\n",
    "    data = per_game.merge(avancados, on=['Player','Season','Tm'], how='left', validate='1:1')\n",
    "    data = data.merge(totals, on=['Player','Season','Tm'], how='left', validate='1:1')\n",
    "    \n",
    "    dict_teams = {'Utah Jazz':'UTA','Phoenix Suns':'PHO',\n",
    "                 'Philadelphia 76ers':'PHI','Brooklyn Nets':'BRK',\n",
    "                 'Denver Nuggets':'DEN','Los Angeles Clippers':'LAC',\n",
    "                 'Milwaukee Bucks':'MIL','Dallas Mavericks':'DAL',\n",
    "                 'Los Angeles Lakers':'LAL','Portland Trail Blazers':'POR',\n",
    "                 'Atlanta Hawks':'ATL','New York Knicks':'NYK',\n",
    "                 'Miami Heat':'MIA','Golden State Warriors':'GSW',\n",
    "                 'Memphis Grizzlies':'MEM','Boston Celtics':'BOS',\n",
    "                 'Washington Wizards':'WAS','Indiana Pacers':'IND',\n",
    "                 'Charlotte Hornets':'CHO','Charlotte Bobcats':'CHA',\n",
    "                 'San Antonio Spurs':'SAS','Chicago Bulls':'CHI',\n",
    "                 'New Orleans Pelicans':'NOP','Sacramento Kings':'SAC',\n",
    "                 'Toronto Raptors':'TOR','Minnesota Timberwolves':'MIN',\n",
    "                 'Cleveland Cavaliers':'CLE','Oklahoma City Thunder':'OKC',\n",
    "                 'Orlando Magic':'ORL','Detroit Pistons':'DET',\n",
    "                 'Houston Rockets':'HOU','New Jersey Nets':'NJN',\n",
    "                 'New Orleans Hornets':'NOH','Seattle SuperSonics':'SEA'}\n",
    "    \n",
    "    teams = pd.DataFrame.from_dict(dict_teams, orient='index').reset_index()\n",
    "    teams = teams.rename(columns={'index':'Team',0:'Tm'})\n",
    "    standings = standings.merge(teams, on='Team', how='left', validate='m:1')\n",
    "    wins = (standings['Record'].str.split('-',expand=True)[0]).astype(int)\n",
    "    games = ((standings['Record'].str.split('-',expand=True)[0]).astype(int)+(standings['Record'].str.split('-',expand=True)[1]).astype(int))\n",
    "    standings['PCT'] = wins/games\n",
    "    \n",
    "    data = data.merge(standings, on=['Tm','Season'], how='left', validate='m:1')\n",
    "    \n",
    "    data['Player'] = data['Player'].str.replace('*','')\n",
    "    \n",
    "    mvps = pd.read_csv('/Users/lilgl/Downloads/BrainStation_Final_Project/MVPs.csv')\n",
    "    data = data.merge(mvps, on=['Player','Season'], how='left', validate='m:1').fillna(0)  \n",
    "\n",
    "    data['Player'] = data['Player'].str.split('\\\\', expand=True)[0]\n",
    "    \n",
    "    # Removing duplicate lines from traded players\n",
    "    dataf = pd.DataFrame()\n",
    "    for season in seasons:\n",
    "        data_season = data[data['Season']==season]\n",
    "        data_season = data_season.drop_duplicates(subset=['Player'], keep='first')\n",
    "\n",
    "        dataf = pd.concat([dataf,data_season], ignore_index=True)\n",
    "    \n",
    "    # Filtering the data\n",
    "    dataf = dataf[((dataf['G']>48)&(dataf['PTS_PERGAME']>13.5)&(dataf['MP_PERGAME']>30)\n",
    "                 &(dataf['Seed']<=16)&(dataf['AST_PERGAME']>1)&(dataf['TRB_PERGAME']>3)\n",
    "                 &(dataf['Tm']!='TOT')&(dataf['FG%_PERGAME']>0.37)&(dataf['FGA_PERGAME']>10)\n",
    "                 &(dataf['PER_AVANCADO']>18)) | (dataf['MVP Votes Share']>0)].reset_index(drop=True)\n",
    "    \n",
    "    # Base for the criteria:\n",
    "    # Karl Malone was MVP in 98-99 with 49 games\n",
    "    # Wes Unseld was MVP at 68-69 with 13.8 PPG and with 10.9 FGA\n",
    "    # Steve Nash was MVP at 04-05 with 3.3 REB\n",
    "    # Moses Malone was MVP at 82-83 with 1.3 AST\n",
    "    # Bob Cousy was MVP at 56-57 with 37.8% FG\n",
    "    # Giannis Antetokounmpo was MVP in 19-20 with 30.4 min\n",
    "    # Kareem Abdul-Jabbar was the only MVP not to make the playoffs in 1976 (40-42)\n",
    "    # Dave Cowens was MVP at 72-73 with a PER of 18.1\n",
    "    # Never has an MVP been traded in the middle of the season that he won the award\n",
    "        \n",
    "    dataf = dataf.drop(['Tm','Team','Record'], axis=1)\n",
    "    \n",
    "    return dataf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5a920b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "per_game, totals, advanced, standings = get_data(seasons)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "924062c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = treat_data(per_game, totals, advanced, standings, seasons)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4342c31a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2021-22    25\n",
       "2020-21    25\n",
       "2019-20    25\n",
       "2018-19    25\n",
       "2017-18    25\n",
       "2016-17    25\n",
       "2015-16    25\n",
       "2014-15    25\n",
       "2013-14    25\n",
       "2012-13    25\n",
       "2011-12    25\n",
       "2010-11    25\n",
       "2009-10    25\n",
       "2008-09    25\n",
       "2007-08    25\n",
       "2006-07    25\n",
       "Name: Season, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Season'].value_counts() # Number of players in the data per season\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'PER_ADVANCED'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m data[\u001b[39m'\u001b[39m\u001b[39mSeason\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mvalue_counts() \u001b[39m# Number of players in the data per season\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m data \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39;49msort_values(by\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mPER_ADVANCED\u001b[39;49m\u001b[39m\"\u001b[39;49m, ascending\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m      4\u001b[0m player_strings \u001b[39m=\u001b[39m data[\u001b[39m\"\u001b[39m\u001b[39mPlayer\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39munique()\n\u001b[0;32m      5\u001b[0m player_strings\n",
      "File \u001b[1;32mc:\\Users\\lilgl\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\lilgl\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:6912\u001b[0m, in \u001b[0;36mDataFrame.sort_values\u001b[1;34m(self, by, axis, ascending, inplace, kind, na_position, ignore_index, key)\u001b[0m\n\u001b[0;32m   6908\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mlen\u001b[39m(by):\n\u001b[0;32m   6909\u001b[0m     \u001b[39m# len(by) == 1\u001b[39;00m\n\u001b[0;32m   6911\u001b[0m     by \u001b[39m=\u001b[39m by[\u001b[39m0\u001b[39m]\n\u001b[1;32m-> 6912\u001b[0m     k \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_label_or_level_values(by, axis\u001b[39m=\u001b[39;49maxis)\n\u001b[0;32m   6914\u001b[0m     \u001b[39m# need to rewrap column in Series to apply key function\u001b[39;00m\n\u001b[0;32m   6915\u001b[0m     \u001b[39mif\u001b[39;00m key \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   6916\u001b[0m         \u001b[39m# error: Incompatible types in assignment (expression has type\u001b[39;00m\n\u001b[0;32m   6917\u001b[0m         \u001b[39m# \"Series\", variable has type \"ndarray\")\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\lilgl\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:1850\u001b[0m, in \u001b[0;36mNDFrame._get_label_or_level_values\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1844\u001b[0m     values \u001b[39m=\u001b[39m (\n\u001b[0;32m   1845\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxes[axis]\n\u001b[0;32m   1846\u001b[0m         \u001b[39m.\u001b[39mget_level_values(key)  \u001b[39m# type: ignore[assignment]\u001b[39;00m\n\u001b[0;32m   1847\u001b[0m         \u001b[39m.\u001b[39m_values\n\u001b[0;32m   1848\u001b[0m     )\n\u001b[0;32m   1849\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1850\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key)\n\u001b[0;32m   1852\u001b[0m \u001b[39m# Check for duplicates\u001b[39;00m\n\u001b[0;32m   1853\u001b[0m \u001b[39mif\u001b[39;00m values\u001b[39m.\u001b[39mndim \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n",
      "\u001b[1;31mKeyError\u001b[0m: 'PER_ADVANCED'"
     ]
    }
   ],
   "source": [
    "data['Season'].value_counts() # Number of players in the data per season\n",
    "data = data.sort_values(by=\"PER_ADVANCED\", ascending=False)\n",
    "\n",
    "player_strings = data[\"Player\"].unique()\n",
    "player_strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for metrics\n",
    "def func_metricas(y_test, y_pred, metricas, modelo, season):\n",
    "    rmse = round(np.sqrt(mean_squared_error(y_test, y_pred)),3) # RMSE\n",
    "    r2 = round(r2_score(y_test, y_pred),3) # R²\n",
    "    \n",
    "    dict_met = {'Modelo': [modelo],\n",
    "                'Season': [season],\n",
    "                'RMSE': [rmse],\n",
    "                'R²': [r2]}\n",
    "    \n",
    "    metrica = pd.DataFrame(data=dict_met)\n",
    "    metricas = pd.concat([metricas,metrica])\n",
    "    \n",
    "    return metricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bbe400d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def func_modelos(data, seasons, modelos, n_seasons_to_test):\n",
    "    final_results = pd.DataFrame()\n",
    "    metricas = pd.DataFrame()\n",
    "    best_params = []\n",
    "    i = 1\n",
    "\n",
    "    for season in seasons:\n",
    "\n",
    "        # Separating training and testing bases\n",
    "        season_teste = season\n",
    "\n",
    "        data_train = data[data['Season']!=season_teste]\n",
    "        data_test = data[data['Season']==season_teste]\n",
    "\n",
    "        X_train = data_train.drop(['MVP Votes Share','MVP Rank','Player','Season'], axis=1)\n",
    "        y_train = data_train['MVP Votes Share']\n",
    "\n",
    "        X_test = data_test.drop(['MVP Votes Share','MVP Rank','Player','Season'], axis=1)\n",
    "        y_test = data_test['MVP Votes Share']\n",
    "\n",
    "        initial_results = data_test[['Player','Season','MVP Votes Share','MVP Rank']]\n",
    "        results = initial_results.copy()\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "\n",
    "        scaled_X_train = scaler.fit_transform(X_train)\n",
    "        scaled_X_test = scaler.transform(X_test)\n",
    "\n",
    "        for modelo in modelos:\n",
    "            # Creating instance for each model\n",
    "            if modelo=='SVM':\n",
    "                param_grid = {'C': [0.001,0.01,0.1,0.5,1,2,5,10],\n",
    "                             'kernel': ['linear','rbf','poly'],\n",
    "                             'gamma': ['scale','auto'],\n",
    "                             'degree': [2,3,4],\n",
    "                             'epsilon': [0.1,0.5,1]}\n",
    "                svr_model = SVR()\n",
    "                grid = GridSearchCV(svr_model, param_grid)\n",
    "                grid.fit(scaled_X_train, y_train)\n",
    "                model = SVR(**grid.best_params_)\n",
    "                best_params.append(grid.best_params_)\n",
    "\n",
    "            elif modelo=='Elastic Net':\n",
    "                param_grid = {'alpha':[0.01,0.1,1,5,10,50,100],\n",
    "                              'l1_ratio':[0.01,0.1,0.5,0.7,0.95,0.99,1]}\n",
    "                elastic_net_model = ElasticNet()\n",
    "                grid = GridSearchCV(elastic_net_model, param_grid)\n",
    "                grid.fit(scaled_X_train, y_train)\n",
    "                grid.best_params_\n",
    "                model = ElasticNet(**grid.best_params_)\n",
    "                best_params.append(grid.best_params_)\n",
    "                \n",
    "            elif modelo=='Random Forest':\n",
    "                param_grid = {'n_estimators': [15,25,50,64,100,150,200],\n",
    "                             'max_features': [2,3,4,5],\n",
    "                             'bootstrap': [True,False],\n",
    "                             'oob_score': [True]}\n",
    "                rfc = RandomForestRegressor()\n",
    "                grid = GridSearchCV(rfc, param_grid)\n",
    "                grid.fit(scaled_X_train, y_train)\n",
    "                model = RandomForestRegressor(**grid.best_params_)\n",
    "                best_params.append(grid.best_params_)\n",
    "                \n",
    "            elif modelo=='AdaBoost':\n",
    "                param_grid = {'n_estimators': [5,10,20,30,40,50,100],\n",
    "                             'learning_rate': [0.01,0.05,0.1,0.2,0.5]}\n",
    "                ada_model = AdaBoostRegressor()\n",
    "                grid = GridSearchCV(ada_model, param_grid)\n",
    "                grid.fit(scaled_X_train, y_train)\n",
    "                model = AdaBoostRegressor(**grid.best_params_)\n",
    "                best_params.append(grid.best_params_)\n",
    "                \n",
    "            elif modelo=='Gradient Boosting':\n",
    "                param_grid = {'n_estimators': [10,20,30,40,50],\n",
    "                             'learning_rate': [0.01,0.05,0.1,0.2,0.5],\n",
    "                             'max_depth': [3,4,5]}\n",
    "                gb_model = GradientBoostingRegressor()\n",
    "                grid = GridSearchCV(gb_model, param_grid)\n",
    "                grid.fit(scaled_X_train, y_train)\n",
    "                model = GradientBoostingRegressor(**grid.best_params_)\n",
    "                best_params.append(grid.best_params_)\n",
    "                \n",
    "            elif modelo=='LGBM':\n",
    "                param_grid = {'learning_rate':[0.01,0.1,0.2,0.3],\n",
    "                              'num_leaves':[5,10,20,30],\n",
    "                              'min_data_in_leaf':[10,25,50],\n",
    "                              'max_depth':[2,3,4],\n",
    "                              'feature_fraction':[0.6,0.7,0.8,0.9],\n",
    "                              'min_gain_to_split':[0,0.01,0.1,0.2],\n",
    "                              'verbose':[-1]}\n",
    "                lgbm_model = LGBMRegressor()\n",
    "                grid = GridSearchCV(lgbm_model, param_grid)\n",
    "                grid.fit(scaled_X_train, y_train)\n",
    "                model = LGBMRegressor(**grid.best_params_)\n",
    "                best_params.append(grid.best_params_)\n",
    "                \n",
    "            model.fit(scaled_X_train, y_train)\n",
    "            \n",
    "            pickle.dump(model,open(path_data+sep+'Modelos'+sep+modelo+'.dat'),'wb')\n",
    "            \n",
    "            y_pred = model.predict(scaled_X_test)\n",
    "            metricas = func_metricas(y_test, y_pred, metricas, modelo, season)\n",
    "\n",
    "            apoio = initial_results.copy()\n",
    "            apoio['Predicted MVP Share '+modelo] = pd.Series(y_pred).values\n",
    "\n",
    "            results_sorted = apoio.sort_values(by='Predicted MVP Share '+modelo,\n",
    "                                                ascending=False).reset_index(drop=True)\n",
    "            results_sorted['MVP Rank '+modelo] = results_sorted.index+1\n",
    "\n",
    "            results = results.merge(results_sorted, on=['Player','Season','MVP Votes Share','MVP Rank'])\n",
    "\n",
    "        final_results = pd.concat([final_results,results], ignore_index=True)\n",
    "\n",
    "        if i == n_seasons_to_test:\n",
    "            break\n",
    "\n",
    "        i = i + 1\n",
    "    \n",
    "    # np.savetxt(path_data+sep+r'Modelos\\params.csv', best_params, delimiter =', ', fmt ='% s')\n",
    "    \n",
    "    return final_results, metricas, best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99acbc60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def media_metricas(metricas):\n",
    "    # Averages of each of the models\n",
    "    final_metricas = pd.DataFrame()\n",
    "    for modelo in metricas['Modelo'].unique():\n",
    "        metrica = metricas[metricas['Modelo']==modelo]\n",
    "        rmse = round(metrica['RMSE'].mean(),3)\n",
    "        r2 = round(metrica['R²'].mean(),3)\n",
    "\n",
    "        dict_met = {'Modelo': [modelo],\n",
    "                    'RMSE': [rmse],\n",
    "                    'R²': [r2]}\n",
    "\n",
    "        apoio = pd.DataFrame(data=dict_met)\n",
    "        final_metricas = pd.concat([final_metricas,apoio], ignore_index=True)\n",
    "    return final_metricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c2ea24b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'jokicni01'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m final_results, metricas, best_params \u001b[39m=\u001b[39m func_modelos(data, seasons, modelos, \u001b[39m1\u001b[39;49m)\n\u001b[0;32m      2\u001b[0m final_metricas \u001b[39m=\u001b[39m media_metricas(metricas)\n\u001b[0;32m      3\u001b[0m final_metricas\n",
      "Cell \u001b[1;32mIn[22], line 26\u001b[0m, in \u001b[0;36mfunc_modelos\u001b[1;34m(data, seasons, modelos, n_seasons_to_test)\u001b[0m\n\u001b[0;32m     22\u001b[0m results \u001b[39m=\u001b[39m initial_results\u001b[39m.\u001b[39mcopy()\n\u001b[0;32m     24\u001b[0m scaler \u001b[39m=\u001b[39m StandardScaler()\n\u001b[1;32m---> 26\u001b[0m scaled_X_train \u001b[39m=\u001b[39m scaler\u001b[39m.\u001b[39;49mfit_transform(X_train)\n\u001b[0;32m     27\u001b[0m scaled_X_test \u001b[39m=\u001b[39m scaler\u001b[39m.\u001b[39mtransform(X_test)\n\u001b[0;32m     29\u001b[0m \u001b[39mfor\u001b[39;00m modelo \u001b[39min\u001b[39;00m modelos:\n\u001b[0;32m     30\u001b[0m     \u001b[39m# Creating instance for each model\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\lilgl\\anaconda3\\lib\\site-packages\\sklearn\\utils\\_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[39m@wraps\u001b[39m(f)\n\u001b[0;32m    139\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m--> 140\u001b[0m     data_to_wrap \u001b[39m=\u001b[39m f(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    141\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_to_wrap, \u001b[39mtuple\u001b[39m):\n\u001b[0;32m    142\u001b[0m         \u001b[39m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    143\u001b[0m         \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[39m0\u001b[39m], X, \u001b[39mself\u001b[39m),\n\u001b[0;32m    145\u001b[0m             \u001b[39m*\u001b[39mdata_to_wrap[\u001b[39m1\u001b[39m:],\n\u001b[0;32m    146\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\lilgl\\anaconda3\\lib\\site-packages\\sklearn\\base.py:878\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    874\u001b[0m \u001b[39m# non-optimized default implementation; override when a better\u001b[39;00m\n\u001b[0;32m    875\u001b[0m \u001b[39m# method is possible for a given clustering algorithm\u001b[39;00m\n\u001b[0;32m    876\u001b[0m \u001b[39mif\u001b[39;00m y \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    877\u001b[0m     \u001b[39m# fit method of arity 1 (unsupervised transformation)\u001b[39;00m\n\u001b[1;32m--> 878\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit(X, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\u001b[39m.\u001b[39mtransform(X)\n\u001b[0;32m    879\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    880\u001b[0m     \u001b[39m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[0;32m    881\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\u001b[39m.\u001b[39mtransform(X)\n",
      "File \u001b[1;32mc:\\Users\\lilgl\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:824\u001b[0m, in \u001b[0;36mStandardScaler.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    822\u001b[0m \u001b[39m# Reset internal state before fitting\u001b[39;00m\n\u001b[0;32m    823\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()\n\u001b[1;32m--> 824\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpartial_fit(X, y, sample_weight)\n",
      "File \u001b[1;32mc:\\Users\\lilgl\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:861\u001b[0m, in \u001b[0;36mStandardScaler.partial_fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    858\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_params()\n\u001b[0;32m    860\u001b[0m first_call \u001b[39m=\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mn_samples_seen_\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 861\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n\u001b[0;32m    862\u001b[0m     X,\n\u001b[0;32m    863\u001b[0m     accept_sparse\u001b[39m=\u001b[39;49m(\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mcsc\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m    864\u001b[0m     dtype\u001b[39m=\u001b[39;49mFLOAT_DTYPES,\n\u001b[0;32m    865\u001b[0m     force_all_finite\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mallow-nan\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    866\u001b[0m     reset\u001b[39m=\u001b[39;49mfirst_call,\n\u001b[0;32m    867\u001b[0m )\n\u001b[0;32m    868\u001b[0m n_features \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]\n\u001b[0;32m    870\u001b[0m \u001b[39mif\u001b[39;00m sample_weight \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\lilgl\\anaconda3\\lib\\site-packages\\sklearn\\base.py:565\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    563\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mValidation should be done on X, y or both.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    564\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m no_val_y:\n\u001b[1;32m--> 565\u001b[0m     X \u001b[39m=\u001b[39m check_array(X, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mX\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_params)\n\u001b[0;32m    566\u001b[0m     out \u001b[39m=\u001b[39m X\n\u001b[0;32m    567\u001b[0m \u001b[39melif\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_y:\n",
      "File \u001b[1;32mc:\\Users\\lilgl\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:879\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    877\u001b[0m         array \u001b[39m=\u001b[39m xp\u001b[39m.\u001b[39mastype(array, dtype, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m    878\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 879\u001b[0m         array \u001b[39m=\u001b[39m _asarray_with_order(array, order\u001b[39m=\u001b[39;49morder, dtype\u001b[39m=\u001b[39;49mdtype, xp\u001b[39m=\u001b[39;49mxp)\n\u001b[0;32m    880\u001b[0m \u001b[39mexcept\u001b[39;00m ComplexWarning \u001b[39mas\u001b[39;00m complex_warning:\n\u001b[0;32m    881\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    882\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mComplex data not supported\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(array)\n\u001b[0;32m    883\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39mcomplex_warning\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\lilgl\\anaconda3\\lib\\site-packages\\sklearn\\utils\\_array_api.py:185\u001b[0m, in \u001b[0;36m_asarray_with_order\u001b[1;34m(array, dtype, order, copy, xp)\u001b[0m\n\u001b[0;32m    182\u001b[0m     xp, _ \u001b[39m=\u001b[39m get_namespace(array)\n\u001b[0;32m    183\u001b[0m \u001b[39mif\u001b[39;00m xp\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m \u001b[39min\u001b[39;00m {\u001b[39m\"\u001b[39m\u001b[39mnumpy\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mnumpy.array_api\u001b[39m\u001b[39m\"\u001b[39m}:\n\u001b[0;32m    184\u001b[0m     \u001b[39m# Use NumPy API to support order\u001b[39;00m\n\u001b[1;32m--> 185\u001b[0m     array \u001b[39m=\u001b[39m numpy\u001b[39m.\u001b[39;49masarray(array, order\u001b[39m=\u001b[39;49morder, dtype\u001b[39m=\u001b[39;49mdtype)\n\u001b[0;32m    186\u001b[0m     \u001b[39mreturn\u001b[39;00m xp\u001b[39m.\u001b[39masarray(array, copy\u001b[39m=\u001b[39mcopy)\n\u001b[0;32m    187\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\lilgl\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:2070\u001b[0m, in \u001b[0;36mNDFrame.__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m   2069\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__array__\u001b[39m(\u001b[39mself\u001b[39m, dtype: npt\u001b[39m.\u001b[39mDTypeLike \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m np\u001b[39m.\u001b[39mndarray:\n\u001b[1;32m-> 2070\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39;49masarray(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_values, dtype\u001b[39m=\u001b[39;49mdtype)\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'jokicni01'"
     ]
    }
   ],
   "source": [
    "final_results, metricas, best_params = func_modelos(data, seasons, modelos, 1)\n",
    "final_metricas = media_metricas(metricas)\n",
    "final_metricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
